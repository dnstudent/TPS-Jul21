from lib.data.utils import train_data, targets, features, split_dataframe
from lib.data.plot import plot_predictions
from lib.models import DummyModel, PollutionEstimator
from lib.models.insta import PollutionDensePredictor
from lib.models.forecast import PollutionRnn

import tensorflow as tf
from keras.callbacks import TensorBoard as TB, EarlyStopping as ES
import pandas as pd
import seaborn as sns
sns.set_theme("notebook", style="whitegrid", rc={"figure.dpi": 72})

data_dir = "../data/"

df = train_data(data_dir, delta=False)
(train_df, train_split), test_df = split_dataframe(df, 0.2, 0.0)


compilation_kwargs = {"loss": "mse"}
with tf.device("/CPU:0"):
    model = PollutionRnn()
    estimator = PollutionEstimator(features, targets, input_days=model.input_days, output_days=model.output_days,
                                   offset_hours=model.offset_hours, shift_hours=model.shift_hours, pollution_model=model, compilation_kwargs=compilation_kwargs)
    estimator.compile(**compilation_kwargs)


with tf.device("/CPU:0"):
    estimator.train(train_df, 5, callbacks=[TB("../logs"), ES(patience=30, restore_best_weights=True)])


import numpy as np
model(np.expand_dims(train_df[features].iloc[:72].to_numpy(), 0))



dates = pd.date_range("2019-01-01", "2019-04", freq="H")
df = pd.DataFrame(list(range(len(dates))), index=dates, columns=["c"])



from lib.data.windowed_data import WTSMaker

wts = WTSMaker(["c"], ["c"], 1, 1/24, 24-1, 1)



import numpy as np
c = 0
for w in wts.supervised_dataset(df):
    c += 1
print(c)
for w in wts.supervised_dataset(df).shuffle(1000).take(2):
    print(w[0].numpy().shape, w[1].numpy().shape)
    print(w[0].numpy()[:, 0], " => ", w[1].numpy()[:, 0])
    # print(np.hstack([w[0].numpy(), w[1].numpy()]))




